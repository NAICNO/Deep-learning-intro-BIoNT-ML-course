{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Shallow Neural Network\n",
    "\n",
    "Here, we define a simple, shallow neural network with three hidden units, like the one we had in our example.\n",
    "First, we define the model layers and the 'forward pass'. Next, we instantiate the model, and pass a one-dimensional tensor with value 1.0 through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class ShallowNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(1, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pre_act = self.hidden(x)\n",
    "        hidden = F.relu(pre_act)\n",
    "        output = self.output(hidden)\n",
    "        return output, pre_act, hidden\n",
    "\n",
    "# Create an instance of the network\n",
    "shallow_model = ShallowNN()\n",
    "\n",
    "# Example input\n",
    "x = torch.tensor([[1.0]], dtype=torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "output, *_ = shallow_model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output value: {output.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta10, theta11 = -0.2, 1.0\n",
    "theta20, theta21 = 1.2, -1.5\n",
    "theta30, theta31 = -2.0, 5.0\n",
    "\n",
    "phi0, phi1, phi2, phi3 = 0.0, 0.9, 1.6, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model.hidden.weight = nn.Parameter(torch.tensor([[theta11, theta21, theta31]]).reshape(3, 1), requires_grad=False)\n",
    "shallow_model.hidden.bias = nn.Parameter(torch.tensor([theta10, theta20, theta30]).reshape(1, 3), requires_grad=False)\n",
    "\n",
    "shallow_model.output.weight = nn.Parameter(torch.tensor([[phi1, phi2, phi3]]).reshape(1, 3), requires_grad=False)\n",
    "shallow_model.output.bias = nn.Parameter(torch.tensor([phi0]), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.linspace(0, 1, 100).reshape(-1, 1)\n",
    "\n",
    "yy, pre_act, hidden = shallow_model(xx)\n",
    "\n",
    "pre_act = pre_act.detach().numpy()\n",
    "hidden = hidden.detach().numpy()\n",
    "yy = yy.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"pre1\", \"pre2\", \"pre3\"],\n",
    "        [\"h1\", \"h2\", \"h3\"],\n",
    "        [\"post1\", \"post2\", \"post3\"],\n",
    "        [\".\", \"y\", \".\"]\n",
    "    ],\n",
    "    figsize=(12, 8),\n",
    ")\n",
    "\n",
    "axes[\"pre1\"].plot(xx, pre_act[:, 0])\n",
    "axes[\"pre1\"].set_title(r\"$\\theta_{10} + \\theta_{11} x$\")\n",
    "axes[\"pre2\"].plot(xx, pre_act[:, 1])\n",
    "axes[\"pre2\"].set_title(r\"$\\theta_{20} + \\theta_{21} x$\")\n",
    "axes[\"pre3\"].plot(xx, pre_act[:, 2])\n",
    "axes[\"pre3\"].set_title(r\"$\\theta_{30} + \\theta_{31} x$\")\n",
    "\n",
    "axes[\"h1\"].plot(xx, hidden[:, 0])\n",
    "axes[\"h1\"].set_title(r\"$\\text{ReLU}(\\theta_{10} + \\theta_{11} x)$\")\n",
    "axes[\"h2\"].plot(xx, hidden[:, 1])\n",
    "axes[\"h2\"].set_title(r\"$\\text{ReLU}(\\theta_{20} + \\theta_{21} x)$\")\n",
    "axes[\"h3\"].plot(xx, hidden[:, 2])\n",
    "axes[\"h3\"].set_title(r\"$\\text{ReLU}(\\theta_{30} + \\theta_{31} x)$\")\n",
    "\n",
    "axes[\"post1\"].plot(xx, phi1 * hidden[:, 0])\n",
    "axes[\"post1\"].set_title(r\"$\\phi_{1} \\text{ReLU}(\\theta_{10} + \\theta_{11} x)$\")\n",
    "axes[\"post2\"].plot(xx, phi2 * hidden[:, 1])\n",
    "axes[\"post2\"].set_title(r\"$\\phi_{2} \\text{ReLU}(\\theta_{20} + \\theta_{21} x)$\")\n",
    "axes[\"post3\"].plot(xx, phi3 * hidden[:, 2])\n",
    "axes[\"post3\"].set_title(r\"$\\phi_{3} \\text{ReLU}(\\theta_{30} + \\theta_{31} x)$\")\n",
    "\n",
    "axes[\"y\"].plot(xx, yy)\n",
    "axes[\"y\"].set_title(r\"$y$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(1, 3)\n",
    "        self.output_1 = nn.Linear(3, 1)\n",
    "\n",
    "        self.linear_2 = nn.Linear(1, 3)\n",
    "        self.output_2 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        pre_act_1 = self.linear_1(x)\n",
    "        hidden_1 = F.relu(pre_act_1)\n",
    "\n",
    "        # Output 1\n",
    "        output_1 = self.output_1(hidden_1)\n",
    "\n",
    "        # Layer 2\n",
    "        pre_act_2 = self.linear_2(output_1)\n",
    "        hidden_2 = F.relu(pre_act_2)\n",
    "\n",
    "        # Output layer\n",
    "        output_2 = self.output_2(hidden_2)\n",
    "\n",
    "        return output_2, pre_act_1, hidden_1, output_1, pre_act_2, hidden_2\n",
    "    \n",
    "\n",
    "deep_model = DeepNN()\n",
    "\n",
    "x = torch.tensor([[1.0]], dtype=torch.float32)\n",
    "\n",
    "output, *_ = deep_model(x)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta10, theta11 = -0.2, 1.0\n",
    "theta20, theta21 = 1.2, -1.5\n",
    "theta30, theta31 = -2.0, 5.0\n",
    "\n",
    "beta10, beta11 = -0.2, 1.0\n",
    "beta20, beta21 = 1.2, -1.5\n",
    "beta30, beta31 = -2.0, 5.0\n",
    "\n",
    "phi0, phi1, phi2, phi3 = 0.0, 0.9, 1.6, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.linear_1.weight = nn.Parameter(torch.tensor([[theta11, theta21, theta31]]).reshape(3, 1), requires_grad=False)\n",
    "deep_model.linear_1.bias = nn.Parameter(torch.tensor([theta10, theta20, theta30]).reshape(1, 3), requires_grad=False)\n",
    "\n",
    "deep_model.output_1.weight = nn.Parameter(torch.tensor([[phi1, phi2, phi3]]).reshape(1, 3), requires_grad=False)\n",
    "deep_model.output_1.bias = nn.Parameter(torch.tensor([phi0]), requires_grad=False)\n",
    "\n",
    "deep_model.linear_2.weight = nn.Parameter(torch.tensor([[beta11, beta21, beta31]]).reshape(3, 1), requires_grad=False)\n",
    "deep_model.linear_2.bias = nn.Parameter(torch.tensor([beta10, beta20, beta30]).reshape(1, 3), requires_grad=False)\n",
    "\n",
    "deep_model.output_2.weight = nn.Parameter(torch.tensor([[phi1, phi2, phi3]]).reshape(1, 3), requires_grad=False)\n",
    "deep_model.output_2.bias = nn.Parameter(torch.tensor([phi0]), requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.linspace(0, 1, 100).reshape(-1, 1)\n",
    "\n",
    "\n",
    "yy, pre_act_1, hidden_1, output_1, pre_act_2, hidden_2 = deep_model(xx)\n",
    "\n",
    "yy = yy.detach().numpy()\n",
    "pre_act_1 = pre_act_1.detach().numpy()\n",
    "hidden_1 = hidden_1.detach().numpy()\n",
    "output_1 = output_1.detach().numpy()\n",
    "pre_act_2 = pre_act_2.detach().numpy()\n",
    "hidden_2 = hidden_2.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"pre_act1_1\", \"pre_act1_2\", \"pre_act1_3\"],\n",
    "        [\"hidden1_1\", \"hidden1_2\", \"hidden1_3\"],\n",
    "        [\".\", \"output1\", \".\"],\n",
    "        [\"pre_act2_1\", \"pre_act2_2\", \"pre_act2_3\"],\n",
    "        [\"hidden2_1\", \"hidden2_2\", \"hidden2_3\"],\n",
    "        [\".\", \"output2\", \".\"],\n",
    "        [\".\", \"y\", \".\"]\n",
    "    ],\n",
    "    figsize=(15, 12),\n",
    ")\n",
    "\n",
    "# First layer pre-activations\n",
    "axes[\"pre_act1_1\"].plot(xx, pre_act_1[:, 0])\n",
    "axes[\"pre_act1_1\"].set_title(r\"$\\theta_{10} + \\theta_{11} x$\")\n",
    "axes[\"pre_act1_2\"].plot(xx, pre_act_1[:, 1])\n",
    "axes[\"pre_act1_2\"].set_title(r\"$\\theta_{20} + \\theta_{21} x$\")\n",
    "axes[\"pre_act1_3\"].plot(xx, pre_act_1[:, 2])\n",
    "axes[\"pre_act1_3\"].set_title(r\"$\\theta_{30} + \\theta_{31} x$\")\n",
    "\n",
    "# First layer hidden activations\n",
    "axes[\"hidden1_1\"].plot(xx, hidden_1[:, 0])\n",
    "axes[\"hidden1_1\"].set_title(r\"$\\text{ReLU}(\\theta_{10} + \\theta_{11} x)$\")\n",
    "axes[\"hidden1_2\"].plot(xx, hidden_1[:, 1])\n",
    "axes[\"hidden1_2\"].set_title(r\"$\\text{ReLU}(\\theta_{20} + \\theta_{21} x)$\")\n",
    "axes[\"hidden1_3\"].plot(xx, hidden_1[:, 2])\n",
    "axes[\"hidden1_3\"].set_title(r\"$\\text{ReLU}(\\theta_{30} + \\theta_{31} x)$\")\n",
    "\n",
    "# First layer output\n",
    "axes[\"output1\"].plot(xx, output_1)\n",
    "axes[\"output1\"].set_title(\"First Layer Output\")\n",
    "\n",
    "# Second layer pre-activations\n",
    "axes[\"pre_act2_1\"].plot(xx, pre_act_2[:, 0])\n",
    "axes[\"pre_act2_1\"].set_title(r\"$\\beta_{10} + \\beta_{11} x$\")\n",
    "axes[\"pre_act2_2\"].plot(xx, pre_act_2[:, 1])\n",
    "axes[\"pre_act2_2\"].set_title(r\"$\\beta_{20} + \\beta_{21} x$\")\n",
    "axes[\"pre_act2_3\"].plot(xx, pre_act_2[:, 2])\n",
    "axes[\"pre_act2_3\"].set_title(r\"$\\beta_{30} + \\beta_{31} x$\")\n",
    "\n",
    "# Second layer hidden activations\n",
    "axes[\"hidden2_1\"].plot(xx, hidden_2[:, 0])\n",
    "axes[\"hidden2_1\"].set_title(r\"$\\text{ReLU}(\\beta_{10} + \\beta_{11} x)$\")\n",
    "axes[\"hidden2_2\"].plot(xx, hidden_2[:, 1])\n",
    "axes[\"hidden2_2\"].set_title(r\"$\\text{ReLU}(\\beta_{20} + \\beta_{21} x)$\")\n",
    "axes[\"hidden2_3\"].plot(xx, hidden_2[:, 2])\n",
    "axes[\"hidden2_3\"].set_title(r\"$\\text{ReLU}(\\beta_{30} + \\beta_{31} x)$\")\n",
    "\n",
    "# Final outputs\n",
    "axes[\"output2\"].plot(xx, yy)\n",
    "axes[\"output2\"].set_title(\"Second Layer Output\")\n",
    "axes[\"y\"].plot(xx, yy)\n",
    "axes[\"y\"].set_title(\"Final Output\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
